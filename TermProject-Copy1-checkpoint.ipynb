{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Torch device selected:  cuda\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-a0fb019d6b7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m     \u001b[0mrun_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-68-a0fb019d6b7a>\u001b[0m in \u001b[0;36mrun_main\u001b[1;34m(FLAGS)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;31m# Run training for n_epochs specified in config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         train_loss, train_accuracy = train(model, device, train_loader,\n\u001b[0m\u001b[0;32m    397\u001b[0m                                             optimizer, criterion, epoch, FLAGS.batch_size)\n\u001b[0;32m    398\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-a0fb019d6b7a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, criterion, epoch, batch_size)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;31m#target = torch.FloatTensor(target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoImgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingDataIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoLabelList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-a0fb019d6b7a>\u001b[0m in \u001b[0;36mtoImgs\u001b[1;34m(ids, imgArray)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m#imgList = torch.from_numpy(imgList).type(torch.FloatTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m#print(len(imgList))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mimgList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;31m#imgList = torch.stack(imgList).float()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimgList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#import sys\n",
    "#from pycocotools.coco import COCO\n",
    "#import requests\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import os\n",
    "\n",
    "\n",
    "dataDir = 'Users/amand/anaconda3/Lib/site-packages/pycocotools/coco'\n",
    "dataType = 'train2017'\n",
    "annFile = '{}/annotations_trainval2017/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "\n",
    "\n",
    "annFile = './Lib/site-packages/pycocotools/coco/annotations_trainval2017/annotations/instances_train2017.json'\n",
    "\n",
    "coco = COCO(annFile)\n",
    "\n",
    "#annFile = 'Users/amand/anaconda3/Lib/site-packages/pycocotools/coco/annotations_trainval2017/annotations/instances_train2017.json'\n",
    "\n",
    "\n",
    "catIds = coco.getCatIds(catNms=['person', 'bench', 'handbag'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "size = len(imgIds)\n",
    "\n",
    "training_num = int(size * .80)\n",
    "\n",
    "trainingDataIds = imgIds[:training_num]\n",
    "testDataIds = imgIds[training_num:]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "'''\n",
    "def splitData(data, labels):\n",
    "\n",
    "  size = labels.size\n",
    "\n",
    "  training_num = int(size * .80)\n",
    "\n",
    "  training_data = data[:training_num,]\n",
    "  training_labels = labels[:training_num,]\n",
    "\n",
    "  test_data = data[training_num:]\n",
    "  test_labels = labels[training_num:]\n",
    "\n",
    "  return training_data, training_labels, test_data, test_labels\n",
    "'''\n",
    "def my_collate()\n",
    "\n",
    "def getMultiHot(labels):\n",
    "  multiHot = [0, 0, 0]\n",
    "  d = {\n",
    "      \"person\": 0,\n",
    "      \"bench\": 1,\n",
    "      \"handbag\": 2\n",
    "  }\n",
    "  for i in labels:\n",
    "    if i in d:\n",
    "        #print(i)\n",
    "        multiHot[d[i]] = 1\n",
    "  #print(multiHot)\n",
    "  #multiHot = torch.zeros(len(labels), 3).scatter(1, multiHot, 1.)\n",
    "  return multiHot\n",
    "\n",
    "def getLabels(catId):\n",
    "    \n",
    "    labelList = []\n",
    "    \n",
    "    list_anns = coco.getAnnIds(catId)\n",
    "    annotations = coco.loadAnns(list_anns)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        labelList.append(coco.loadCats(annotation['category_id'])[0]['name'])\n",
    "              \n",
    "    return labelList\n",
    "\n",
    "def toImgs(ids, imgArray):\n",
    "    \n",
    "    imgList = []\n",
    "    \n",
    "    for i in ids:\n",
    "        img = coco.loadImgs(i.item())[0]\n",
    "        img = coco.loadImgs(imgArray[np.random.randint(0,len(imgArray))])[0]\n",
    "        img = io.imread(img['coco_url'])\n",
    "        img = torch.from_numpy(img)\n",
    "        \n",
    "        '''\n",
    "        #print(img.shape)\n",
    "        img = img.permute(2, 0, 1)\n",
    "        img = img.numpy()\n",
    "        img = np.insert(img, 0, FLAGS.batch_size, axis=0)\n",
    "        print(img.shape)\n",
    "        '''\n",
    "        \n",
    "        imgList.append(img)\n",
    "        \n",
    "        \n",
    "    #imgList = torch.from_numpy(imgList).type(torch.FloatTensor)\n",
    "    #print(len(imgList))\n",
    "    imgList = torch.FloatTensor(imgList)\n",
    "    #imgList = torch.stack(imgList).float()\n",
    "    return imgList\n",
    "\n",
    "def toLabelList(ids):\n",
    "    labelList = []\n",
    "\n",
    "    for i in ids:\n",
    "        labelList.append(getMultiHot(getLabels(i.item())))\n",
    "        \n",
    "    labelList = torch.FloatTensor(labelList)\n",
    "    return labelList\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, mode):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Convolutional network with 2 additional layers\n",
    "        # self.conv1 = nn.Conv2D(...)\n",
    "        self.conv1 = nn.Conv2d(3,16,5)\n",
    "        self.conv2 = nn.Conv2d(16,64,5)\n",
    "        self.conv3 = nn.Conv2d(64,128, 5)\n",
    "        self.conv4 = nn.Conv2d(128,256, 5)\n",
    "        self.conv5 = nn.Conv2d(256,256, 5)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*10*10, 128) \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 16)\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "\n",
    "\n",
    "        \n",
    "        if mode == 4:\n",
    "            self.forward = self.model_4\n",
    "        else: \n",
    "            print(\"Invalid mode \", mode, \"selected. Select between 1-5\")\n",
    "            exit(0)\n",
    "        \n",
    "\n",
    "    def model_4(self, X):\n",
    "        \n",
    "        def num_flat_features(X):\n",
    "            size = X.size()[1:]\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "              num_features *= s\n",
    "            return num_features\n",
    "\n",
    "        X = self.conv1(X)\n",
    "        X = F.max_pool2d(self.conv2(X), (2, 2), stride=1) \n",
    "        X = self.conv3(X)\n",
    "        X = self.conv4(X)\n",
    "        X = F.max_pool2d(self.conv5(X), (2, 2), stride=1)\n",
    "        print(X.shape)\n",
    "        X = X.view(-1, num_flat_features(X))\n",
    "        X = F.relu(self.fc1(X))\n",
    "        #X = self.fc2(X)\n",
    "        X = self.dropout(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        X = F.relu(self.fc4(X))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import numpy as np\n",
    "#from google.colab import files\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch, batch_size):\n",
    "    '''\n",
    "    Trains the model for an epoch and optimizes it.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    train_loader: dataloader for training samples.\n",
    "    optimizer: optimizer to use for model parameter updates.\n",
    "    criterion: used to compute loss for prediction and target \n",
    "    epoch: Current epoch to train for.\n",
    "    batch_size: Batch size to be used.\n",
    "    '''\n",
    "    \n",
    "    # Set model to train mode before each epoch\n",
    "    model.train()\n",
    "    \n",
    "    # Empty list to store losses \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    \n",
    "    # Iterate over entire training samples (1 epoch)\n",
    "    for batch_idx, batch_sample in enumerate(train_loader):\n",
    "        #data, target = batch_sample\n",
    "        \n",
    "        #print(batch_sample.item())\n",
    "        \n",
    "        #img = coco.loadImgs(batch_sample.item())[0]\n",
    "        #img = coco.loadImgs(trainingDataIds[np.random.randint(0,len(trainingDataIds))])[0]\n",
    "        #img = io.imread(img['coco_url'])\n",
    "        #print(img)\n",
    "        \n",
    "        #data = img\n",
    "        #data = torch.from_numpy(data)\n",
    "        #print(data.size())\n",
    "        \n",
    "        #target = getMultiHot(getLabels(batch_sample.item()))\n",
    "        #target = torch.FloatTensor(target)\n",
    "        \n",
    "        data = toImgs(batch_sample, trainingDataIds)\n",
    "        \n",
    "        target = toLabelList(batch_sample)\n",
    "        \n",
    "        \n",
    "        # Push data/label to correct device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Do forward pass for current set of data\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute loss based on criterion\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Computes gradient based on final loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Store loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Optimize model parameters based on learning rate and gradient \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get predicted index by selecting maximum log-probability\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        # adds one to correct for every correct prediction\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "    train_loss = float(np.mean(losses))\n",
    "    train_acc = correct / ((batch_idx+1) * batch_size)\n",
    "    print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        float(np.mean(losses)), correct, (batch_idx+1) * batch_size,\n",
    "        100. * correct / ((batch_idx+1) * batch_size)))\n",
    "    return train_loss, train_acc\n",
    "    \n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    '''\n",
    "    Tests the model.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    test_loader: dataloader for test samples.\n",
    "    '''\n",
    "    \n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    \n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(test_loader):\n",
    "            #data, target = sample\n",
    "            \n",
    "            #img = coco.loadImgs(batch_sample)[0]\n",
    "            #img = coco.loadImgs(testDataIds[np.random.randint(0,len(testDataIds))])[0]\n",
    "            #img = io.imread(img['coco_url'])\n",
    "        \n",
    "            #data = img\n",
    "            #data = torch.from_numpy(data)\n",
    "            \n",
    "        \n",
    "            #target = getMultiHot(getLabels(batch_sample))\n",
    "            #target = torch.FloatTensor(target)\n",
    "            \n",
    "            data = toImgs(batch_sample, testDataIds)\n",
    "            target = toLabelList(batch_sample)\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "\n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            # Compute loss based on same criterion as training\n",
    "            loss = nn.BCEwithLogitsLoss(output, target, reduction='sum')\n",
    "            \n",
    "            # Append loss to overall test loss\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Get predicted index by selecting maximum log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "           \n",
    "            # Count correct predictions overall \n",
    "            # adds one to correct for every correct prediction\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "\n",
    "    test_loss = float(np.mean(losses))\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "    \n",
    "\n",
    "def run_main(FLAGS):\n",
    "    # Check if cuda is available\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    # Set proper device based on cuda availability \n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print(\"Torch device selected: \", device)\n",
    "    \n",
    "    # Initialize the model and send to device \n",
    "    model = ConvNet(FLAGS.mode).to(device)\n",
    "    \n",
    "    \n",
    "    # Define loss function.\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "   \n",
    "    # Define optimizer function.\n",
    "    optimizer = optim.SGD(model.parameters(), FLAGS.learning_rate)\n",
    "        \n",
    "    \n",
    "    # Create transformations to apply to each data sample \n",
    "    # Can specify variations such as image flip, color flip, random crop, ...\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    \n",
    "    # Load datasets for training and testing\n",
    "    # Inbuilt datasets available in torchvision (check documentation online)\n",
    "    #dataset1 = datasets.CIFAR10('./data/', train=True, download=True,\n",
    "                       #transform=transform)\n",
    "    #dataset2 = datasets.CIFAR10('./data/', train=False,\n",
    "                      # transform=transform)\n",
    "        \n",
    "    dataset1 = trainingDataIds\n",
    "    dataset2 = testDataIds\n",
    "    train_loader = DataLoader(dataset1, batch_size = FLAGS.batch_size, \n",
    "                                shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset2, batch_size = FLAGS.batch_size, \n",
    "                                shuffle=False, num_workers=4)\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    #writer = SummaryWriter(log_dir=\"Comp Vision\", filename_suffix=\"output.txt\")\n",
    "    \n",
    "    trainData = np.zeros(FLAGS.num_epochs)\n",
    "    testData = np.zeros(FLAGS.num_epochs)\n",
    "\n",
    "\n",
    "    # Run training for n_epochs specified in config \n",
    "    for epoch in range(1, FLAGS.num_epochs + 1):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader,\n",
    "                                            optimizer, criterion, epoch, FLAGS.batch_size)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader)\n",
    "        \n",
    "       # writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "       # writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "       # writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "       # writer.add_scalar('Accuracy/test', test_accuracy, epoch)        \n",
    "       # writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "        \n",
    "        trainData[epoch - 1] = train_accuracy\n",
    "        testData[epoch - 1] = test_accuracy\n",
    "\n",
    "    \n",
    "    #writer.flush()\n",
    "    #writer.close()\n",
    "\n",
    "    #with open('output.txt', 'w') as f:\n",
    "      #f.write(\"TrainLoss: \" + str(train_loss) + \"\\n\")\n",
    "      #f.write(\"TestLoss: \" + str(test_loss) + \"\\n\")\n",
    "      #f.write(\"Train Accuracy: \" + str(train_accuracy) + \"\\n\")\n",
    "      #f.write(\"Test Accuracy: \" + str(test_accuracy) + \"\\n\")\n",
    "      #f.write(\"LR: \" + str(optimizer.param_groups[0]['lr']) + \"\\n\")\n",
    "      #f.write(\"Best Accuracy: \" + str(best_accuracy) + \"\\n\")\n",
    "    #files.download('output.txt')\n",
    "    #f.close()\n",
    "\n",
    "    # Draws the graphs for training and test accuracy\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(trainData, color='red')\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(testData, color='black')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"accuracy is {:2.2f}\".format(best_accuracy))\n",
    "    \n",
    "    print(\"Training and evaluation finished\")\n",
    "\n",
    "    print(\"Output:\")\n",
    "    print(\"TrainLoss: \", train_loss)\n",
    "    print(\"TestLoss: \", test_loss)\n",
    "    print(\"Train Accuracy: \", train_accuracy)\n",
    "    print(\"Test Accuracy: \", test_accuracy)\n",
    "    print(\"LR: \", optimizer.param_groups[0]['lr'])\n",
    "    print(\"Best Accuracy: \", best_accuracy)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Set parameters for Sparse Autoencoder\n",
    "    parser = argparse.ArgumentParser('CNN Exercise.')\n",
    "    parser.add_argument('--mode',\n",
    "                        type=int, default=4,\n",
    "                        help='Select mode between 1-5.') #change model here\n",
    "    parser.add_argument('--learning_rate',\n",
    "                        type=float, default=0.01,\n",
    "                        help='Initial learning rate.') #change learning rate here\n",
    "    parser.add_argument('--num_epochs',\n",
    "                        type=int,\n",
    "                        default=40,\n",
    "                        help='Number of epochs to run trainer.') #change num epochs here\n",
    "    parser.add_argument('--batch_size',\n",
    "                        type=int, default=32,\n",
    "                        help='Batch size. Must divide evenly into the dataset sizes.') #change batch size here\n",
    "    parser.add_argument('--log_dir',\n",
    "                        type=str,\n",
    "                        default='logs',\n",
    "                        help='Directory to put logging.')\n",
    "    \n",
    "    FLAGS = None\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    \n",
    "    run_main(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
